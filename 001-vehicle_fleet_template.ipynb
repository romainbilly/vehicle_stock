{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information regarding the data that this notebook refers to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out the following fields. Check that input data and notebook name match.\n",
    "\n",
    "# reference vehicle_fleet_data.xlsx notebook metadata to select notebook_id\n",
    "notebook_id= '005'\n",
    "name_string= '_s_EU_1996_2018_cl(pc)_wt_eurostat'\n",
    "\n",
    "nb_name= notebook_id + name_string +'.ipynb'\n",
    "nb_input_workbook= 'in' + name_string + '.xlsx'\n",
    "nb_output_workbook= notebook_id + '.xlsx'\n",
    "nb_stock_or_flow= 'stock'\n",
    "nb_geography= '150'\n",
    "nb_start_time= '1996'\n",
    "nb_stop_time= '2018'\n",
    "nb_attribute_1= 'passenger cars'\n",
    "nb_attribute_2= 'registered'\n",
    "nb_attribute_3= 'motor energy'\n",
    "nb_attribute_4= ''\n",
    "nb_data_source= 'EUROSTAT'\n",
    "nb_data_source_url= 'https://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=road_eqs_carpda&lang=en'\n",
    "nb_comment= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the notbook metadata into a data frame\n",
    "notebook_metadata = pd.DataFrame({'notebook_name':nb_name,\n",
    "                                 'input_file': nb_input_workbook, \n",
    "                                 'output_file': nb_output_workbook, \n",
    "                                 'source': nb_data_source, \n",
    "                                 'geography': nb_geography,\n",
    "                                 'start_time': nb_start_time,\n",
    "                                 'stop_time': nb_stop_time, \n",
    "                                 'attribute1': nb_attribute_1, \n",
    "                                 'attribute2': nb_attribute_2,\n",
    "                                 'attribute3': nb_attribute_3,\n",
    "                                 'attribute4': nb_attribute_4,\n",
    "                                 'source_url' : nb_data_source_url,\n",
    "                                 'comment': nb_comment}, index=[notebook_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the excel data and merging the sheets into one dataframe with category info attached to row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data,\n",
    "xls = pd.ExcelFile(nb_input_workbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-ca1fcb828c24>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ca1fcb828c24>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df = pd.read_excel(xls,sheetname= ,header=17, usecols='c,g',nrows=30)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# extract the data into a dataframe or several\n",
    "df = pd.read_excel(xls,sheetname= ,header=17, usecols='c,g',nrows=30)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .dropna() to drop the rows and columns with no data. \n",
    "# thresh=2 drops columns that do contain up to 2 pieces of non NAN values\n",
    "df.dropna(axis=1, thresh=2, inplace=True)\n",
    "df.dropna(axis=0, thresh=2, inplace=True)\n",
    "#drop columns or rows that will not be useful\n",
    "df.drop(columns= 'Variation 2015/2014', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows by location\n",
    "# pd.drop(index=[24,25,26,29], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are multiple sheets to be concatonated into one use pd.concat:\n",
    "df2 = pd.concat([dfa,dfb,dfc,dfe], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dictionary for country codes and replace country names with 3 digit codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename region to 'geo'\n",
    "df.rename(columns={'REGIONS/COUNTRIES':'geo'},inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "\n",
    "# read in data, set the header to be the desired column titles\n",
    "geo_dict = pd.read_excel(dictxls, sheet_name= 'geo_dictionary', index_col= 0)\n",
    "geo_name = geo_dict['name'].str.lower().to_list()\n",
    "country_code = geo_dict['country_code'].astype(str).to_list()\n",
    "region_code = geo_dict['region_code'].astype(str).to_list()\n",
    "geo_dict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the strings in the geo column and replace them with the 3 number codes\n",
    "df['geo']= df.geo.str.lower()\n",
    "df.replace(to_replace= geo_name, value= country_code, inplace=True )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find contries which did not match \n",
    "df.loc[~df['geo'].isin(country_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternately could use\n",
    "# df = df.loc[df['geo'].isin(country_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOTOR ENERGY code replacement\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "me_dict = pd.read_excel(dictxls, sheet_name= 'fuel_types', index_col= 0)\n",
    "me_eurostat = me_dict['eurostat'].to_list()\n",
    "me_code = me_dict['dt_code'].to_list()\n",
    "\n",
    "df['motor_energy'].replace(to_replace=dt_eurostat, value=dt_code, inplace=True )\n",
    "#find codes which did not match \n",
    "df.loc[~df['motor_energy'].isin(dt_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS and FOOTNOTES\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "flag_dict = pd.read_excel(dictxls, sheet_name= 'footnote', index_col= 0)\n",
    "flag_eurostat = flag_dict['flag_eurostat'].to_list()\n",
    "flag_code = flag_dict['flag_code'].to_list()\n",
    "flag_dict.tail(2)\n",
    "\n",
    "df['footnote'].replace(to_replace=flag_code, value=flag_eurostat, inplace=True )\n",
    "#find codes which did not match \n",
    "df.loc[~df['footnote'].isin(flag_eurostat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map weight codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHT CODES\n",
    "# rename to 'weight'\n",
    "df.rename(columns={'WEIGHT':'weight'},inplace= True)\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "weight_dict = pd.read_excel(dictxls, sheet_name= 'weight', index_col= 0)\n",
    "weight_range = weight_dict['weight_range'].to_list()\n",
    "weight_code = weight_dict['weight_code'].to_list()\n",
    "weight_dict.tail(2)\n",
    "\n",
    "df['weight'].replace(to_replace=weight_range, value=weight_code, inplace=True )\n",
    "\n",
    "#find codes which did not match \n",
    "df.loc[~df['weight'].isin(weight_code)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mark no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "what does the missing data mean? Does it mean there were no vehicles of that type? or does it mean that there is no data recorded for that type? \"\"\"\n",
    "'''\n",
    "df.replace(to_replace=':', value='no_data', inplace=True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rearrange data into proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.melt() pivots the table bringing the column headers into a new attribute\n",
    "melt = df.melt(id_vars=['geo'], var_name= 'year')\n",
    "melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structuring the data into format of datastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the data frame to df\n",
    "df=melted\n",
    "# add in a column of indexes\n",
    "df.index = notebook_id + df.index.astype(str).str.zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename or add all necessary columns\n",
    "df.loc[:,'year_of_measurement']= df.loc[:,'year']\n",
    "# date of measurement is concatonated to year of measurement to achieve desired format\n",
    "df.loc[:,'date_of_measurement']=df['year_of_measurement'].astype(str) + '-03-31'\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:,'geo']= \n",
    "df.loc[:,'process']= 'r'\n",
    "df.loc[:,'vehicle_class']= 'all'\n",
    "df.loc[:,'vehicle_segment']='all'\n",
    "df.loc[:,'motor_energy']= 'all'\n",
    "df.loc[:,'model_year']= 'all'\n",
    "df.loc[:,'year_of_first_registraion']=''\n",
    "df.loc[:,'value']= df['value']\n",
    "df.loc[:,'unit']= 'nr'\n",
    "df.loc[:,'source']= nb_data_source\n",
    "df.loc[:,'accessed']= '2020-06-30'\n",
    "df.loc[:,'notebook']= nb_name\n",
    "df.loc[:,'footnote']= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a finalized dataframe for output with columns in arranged order\n",
    "heading_list= ['year_of_measurement','date_of_measurement','geo','process','vehicle_class','vehicle_segment','motor_energy','model_year','year_of_first_registraion','value','unit','source','accessed','notebook','footnote']\n",
    "df_out= df[heading_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_of_measurement</th>\n",
       "      <th>date_of_measurement</th>\n",
       "      <th>geo</th>\n",
       "      <th>process</th>\n",
       "      <th>vehicle_class</th>\n",
       "      <th>vehicle_segment</th>\n",
       "      <th>drive_train</th>\n",
       "      <th>model_year</th>\n",
       "      <th>year_of_first_registraion</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>source</th>\n",
       "      <th>accessed</th>\n",
       "      <th>notebook</th>\n",
       "      <th>footnote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>003000000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>150</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>45053.2</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000001</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>40</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>367</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>56</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>674.465</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>208</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>479</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>246</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>86.69</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001590</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>788</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>460</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001591</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>800</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>340</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001592</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>894</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001593</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>716</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001594</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>335190</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             year_of_measurement date_of_measurement  geo process  \\\n",
       "003000000000                2005          2005-03-31  150       r   \n",
       "003000000001                2005          2005-03-31   40       r   \n",
       "003000000002                2005          2005-03-31   56       r   \n",
       "003000000003                2005          2005-03-31  208       r   \n",
       "003000000004                2005          2005-03-31  246       r   \n",
       "...                          ...                 ...  ...     ...   \n",
       "003000001590                2015          2015-03-31  788       r   \n",
       "003000001591                2015          2015-03-31  800       r   \n",
       "003000001592                2015          2015-03-31  894       r   \n",
       "003000001593                2015          2015-03-31  716       r   \n",
       "003000001594                2015          2015-03-31    1       r   \n",
       "\n",
       "             vehicle_class vehicle_segment drive_train model_year  \\\n",
       "003000000000          OICV             all         all        all   \n",
       "003000000001          OICV             all         all        all   \n",
       "003000000002          OICV             all         all        all   \n",
       "003000000003          OICV             all         all        all   \n",
       "003000000004          OICV             all         all        all   \n",
       "...                    ...             ...         ...        ...   \n",
       "003000001590          OICV             all         all        all   \n",
       "003000001591          OICV             all         all        all   \n",
       "003000001592          OICV             all         all        all   \n",
       "003000001593          OICV             all         all        all   \n",
       "003000001594          OICV             all         all        all   \n",
       "\n",
       "             year_of_first_registraion    value unit source    accessed  \\\n",
       "003000000000                            45053.2   nr   OICA  2020-06-30   \n",
       "003000000001                                367   nr   OICA  2020-06-30   \n",
       "003000000002                            674.465   nr   OICA  2020-06-30   \n",
       "003000000003                                479   nr   OICA  2020-06-30   \n",
       "003000000004                              86.69   nr   OICA  2020-06-30   \n",
       "...                                ...      ...  ...    ...         ...   \n",
       "003000001590                                460   nr   OICA  2020-06-30   \n",
       "003000001591                                340   nr   OICA  2020-06-30   \n",
       "003000001592                                120   nr   OICA  2020-06-30   \n",
       "003000001593                                110   nr   OICA  2020-06-30   \n",
       "003000001594                             335190   nr   OICA  2020-06-30   \n",
       "\n",
       "                                          notebook footnote  \n",
       "003000000000  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000001  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000002  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000003  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000004  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "...                                            ...      ...  \n",
       "003000001590  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001591  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001592  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001593  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001594  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "\n",
       "[1595 rows x 15 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df_out before saving\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## at this point restart kernel and run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an output file named according to notebook id with relevant data and metadata\n",
    "writer = pd.ExcelWriter(nb_output_workbook, engine='xlsxwriter')\n",
    "df_out.to_excel(writer, sheet_name='data', merge_cells=False)\n",
    "notebook_metadata.to_excel(writer, sheet_name= 'notebook_metadata')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the data from the notebook to the stock dataframe and notebook metadata pickles\n",
    "\n",
    "import pickle\n",
    "# load in the stock DataFrame pickle\n",
    "stock_pickle = pd.read_pickle('stock_df.pickle')\n",
    "\n",
    "# concatenate the out_df to the stock_pickle and remove any duplicate rows\n",
    "stock_df = pd.concat([stock_pickle,df_out]).drop_duplicates()\n",
    "\n",
    "# write the updated stock dataframe to pickle\n",
    "stock_df.to_pickle('stock_df.pickle')\n",
    "\n",
    "# repeat the process for the metadata\n",
    "metadata_pickle = pd.read_pickle('metadata_df.pickle')\n",
    "\n",
    "metadata_df = pd.concat([metadata_pickle, notebook_metadata]).drop_duplicates()\n",
    "\n",
    "metadata_df.to_pickle('metadata_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the stock metadata \n",
    "writer = pd.ExcelWriter('vehicle_fleet_stock.xlsx', engine='xlsxwriter')\n",
    "stock_df.to_excel(writer, sheet_name='data', merge_cells=False)\n",
    "metadata_df.to_excel(writer, sheet_name= 'notebook_metadata')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code initializes the pickle files \n",
    "# df_out.to_pickle('stock_df.pickle')\n",
    "# notebook_metadata.to_pickle('metadata_df.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
