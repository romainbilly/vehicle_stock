{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information regarding the data that this notebook refers to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill out the following fields. Check that input data and notebook name match.\n",
    "\n",
    "# reference vehicle_fleet_data.xlsx notebook metadata to select notebook_id\n",
    "notebook_id= '005'\n",
    "name_string= '_s_EU_1996_2018_cl(pc)_wt_eurostat'\n",
    "\n",
    "nb_name= notebook_id + name_string +'.ipynb'\n",
    "nb_input_workbook= 'in' + name_string + '.xlsx'\n",
    "nb_output_workbook= notebook_id + '.xlsx'\n",
    "nb_stock_or_flow= 'stock'\n",
    "nb_geography= '150'\n",
    "nb_start_time= '1996'\n",
    "nb_stop_time= '2018'\n",
    "nb_attribute_1= 'passenger cars'\n",
    "nb_attribute_2= 'registered'\n",
    "nb_attribute_3= 'motor energy'\n",
    "nb_attribute_4= ''\n",
    "nb_data_source= 'EUROSTAT'\n",
    "nb_data_source_url= 'https://appsso.eurostat.ec.europa.eu/nui/show.do?dataset=road_eqs_carpda&lang=en'\n",
    "nb_comment= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the notbook metadata into a data frame\n",
    "notebook_metadata = pd.DataFrame({'notebook_name':nb_name,\n",
    "                                 'input_file': nb_input_workbook, \n",
    "                                 'output_file': nb_output_workbook, \n",
    "                                 'source': nb_data_source, \n",
    "                                 'geography': nb_geography,\n",
    "                                 'start_time': nb_start_time,\n",
    "                                 'stop_time': nb_stop_time, \n",
    "                                 'attribute1': nb_attribute_1, \n",
    "                                 'attribute2': nb_attribute_2,\n",
    "                                 'attribute3': nb_attribute_3,\n",
    "                                 'attribute4': nb_attribute_4,\n",
    "                                 'source_url' : nb_data_source_url,\n",
    "                                 'comment': nb_comment}, index=[notebook_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the excel data and merging the sheets into one dataframe with category info attached to row data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data,\n",
    "inputXls = pd.ExcelFile(nb_input_workbook)\n",
    "metadataXls = pd.ExcelFile('metadata_vehicle_fleet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>GEO</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Value</th>\n",
       "      <th>Flag and Footnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NR</td>\n",
       "      <td>Austria</td>\n",
       "      <td>KG_LT1000</td>\n",
       "      <td>1996</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NR</td>\n",
       "      <td>Austria</td>\n",
       "      <td>KG_LT1000</td>\n",
       "      <td>1997</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NR</td>\n",
       "      <td>Austria</td>\n",
       "      <td>KG_LT1000</td>\n",
       "      <td>1998</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NR</td>\n",
       "      <td>Austria</td>\n",
       "      <td>KG_LT1000</td>\n",
       "      <td>1999</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NR</td>\n",
       "      <td>Austria</td>\n",
       "      <td>KG_LT1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>NR</td>\n",
       "      <td>Kosovo (under United Nations Security Council ...</td>\n",
       "      <td>KG_GE1500</td>\n",
       "      <td>2014</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>NR</td>\n",
       "      <td>Kosovo (under United Nations Security Council ...</td>\n",
       "      <td>KG_GE1500</td>\n",
       "      <td>2015</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>NR</td>\n",
       "      <td>Kosovo (under United Nations Security Council ...</td>\n",
       "      <td>KG_GE1500</td>\n",
       "      <td>2016</td>\n",
       "      <td>:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>NR</td>\n",
       "      <td>Kosovo (under United Nations Security Council ...</td>\n",
       "      <td>KG_GE1500</td>\n",
       "      <td>2017</td>\n",
       "      <td>45993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>NR</td>\n",
       "      <td>Kosovo (under United Nations Security Council ...</td>\n",
       "      <td>KG_GE1500</td>\n",
       "      <td>2018</td>\n",
       "      <td>147512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2208 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UNIT                                                GEO     WEIGHT  TIME  \\\n",
       "0      NR                                            Austria  KG_LT1000  1996   \n",
       "1      NR                                            Austria  KG_LT1000  1997   \n",
       "2      NR                                            Austria  KG_LT1000  1998   \n",
       "3      NR                                            Austria  KG_LT1000  1999   \n",
       "4      NR                                            Austria  KG_LT1000  2000   \n",
       "...   ...                                                ...        ...   ...   \n",
       "2203   NR  Kosovo (under United Nations Security Council ...  KG_GE1500  2014   \n",
       "2204   NR  Kosovo (under United Nations Security Council ...  KG_GE1500  2015   \n",
       "2205   NR  Kosovo (under United Nations Security Council ...  KG_GE1500  2016   \n",
       "2206   NR  Kosovo (under United Nations Security Council ...  KG_GE1500  2017   \n",
       "2207   NR  Kosovo (under United Nations Security Council ...  KG_GE1500  2018   \n",
       "\n",
       "       Value Flag and Footnotes  \n",
       "0          :                NaN  \n",
       "1          :                NaN  \n",
       "2          :                NaN  \n",
       "3          :                NaN  \n",
       "4          :                NaN  \n",
       "...      ...                ...  \n",
       "2203       :                NaN  \n",
       "2204       :                NaN  \n",
       "2205       :                NaN  \n",
       "2206   45993                NaN  \n",
       "2207  147512                NaN  \n",
       "\n",
       "[2208 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the data into a dataframe or several\n",
    "df = pd.read_excel(inputXls)\n",
    "df.rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Variation 2015/2014'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3f80fd28037c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#drop columns or rows that will not be useful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Variation 2015/2014'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3989\u001b[0m         \"\"\"\n\u001b[0;32m-> 3990\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Variation 2015/2014'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# use .dropna() to drop the rows and columns with no data. \n",
    "# thresh=2 drops columns that do contain up to 2 pieces of non NAN values\n",
    "df.dropna(axis=1, thresh=2, inplace=True)\n",
    "df.dropna(axis=0, thresh=2, inplace=True)\n",
    "#drop columns or rows that will not be useful\n",
    "df.drop(columns= 'Variation 2015/2014', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there are multiple sheets to be concatonated into one use pd.concat:\n",
    "df2 = pd.concat([dfa,dfb,dfc,dfe], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-fff2106374e0>:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.geo = df.GEO\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'alternate name 1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'alternate name 1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fff2106374e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGEO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgeoMetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alternate name 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgeoMetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeoMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'alternate name 1'"
     ]
    }
   ],
   "source": [
    "# lowercase the strings in the geo column and replace them with the 3 number codes\n",
    "geoMetadata = pd.read_excel(metadataXls, sheet_name= 'geography_metadata', skiprows=1)\n",
    "\n",
    "df['geo']= df.geo.str.lower()\n",
    "df.geo.replace(to_replace= geoMetadata['alternate name 1'].str.lower().to_list(), value= geoMetadata['name'].to_list(), inplace=True )\n",
    "df[df.name.isin(geoMetadata.name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find contries which did not match \n",
    "df.loc[~df['geo'].isin(country_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternately could use\n",
    "# df = df.loc[df['geo'].isin(country_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOTOR ENERGY code replacement\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "me_dict = pd.read_excel(dictxls, sheet_name= 'fuel_types', index_col= 0)\n",
    "me_eurostat = me_dict['eurostat'].to_list()\n",
    "me_code = me_dict['dt_code'].to_list()\n",
    "\n",
    "df['motor_energy'].replace(to_replace=dt_eurostat, value=dt_code, inplace=True )\n",
    "#find codes which did not match \n",
    "df.loc[~df['motor_energy'].isin(dt_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS and FOOTNOTES\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "flag_dict = pd.read_excel(dictxls, sheet_name= 'footnote', index_col= 0)\n",
    "flag_eurostat = flag_dict['flag_eurostat'].to_list()\n",
    "flag_code = flag_dict['flag_code'].to_list()\n",
    "flag_dict.tail(2)\n",
    "\n",
    "df['footnote'].replace(to_replace=flag_code, value=flag_eurostat, inplace=True )\n",
    "#find codes which did not match \n",
    "df.loc[~df['footnote'].isin(flag_eurostat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map weight codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHT CODES\n",
    "# rename to 'weight'\n",
    "df.rename(columns={'WEIGHT':'weight'},inplace= True)\n",
    "# read in data, skip rows so that headings become column names\n",
    "dictxls = pd.ExcelFile('vehicle_fleet_dictionary.xlsx')\n",
    "# assemble drive train code dictionary\n",
    "weight_dict = pd.read_excel(dictxls, sheet_name= 'weight', index_col= 0)\n",
    "weight_range = weight_dict['weight_range'].to_list()\n",
    "weight_code = weight_dict['weight_code'].to_list()\n",
    "weight_dict.tail(2)\n",
    "\n",
    "df['weight'].replace(to_replace=weight_range, value=weight_code, inplace=True )\n",
    "\n",
    "#find codes which did not match \n",
    "df.loc[~df['weight'].isin(weight_code)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the class_metatdata sheet which has equivalent terms for class types according to source\n",
    "metaxls = pd.ExcelFile('metadata_vehicle_fleet.xlsx')\n",
    "classMetadata = pd.read_excel(metaxls, sheet_name= 'class_metadata', index_col= 0)\n",
    "\n",
    "# limit the data to the rows specific to relevent source\n",
    "sourceClassDict= classMetadata[classMetadata.source == nb_data_source] \n",
    "\n",
    "sourceClassLabel= sourceClassDict.label.to_list()\n",
    "\n",
    "sourceClassCode = sourceClassDict.code.to_list()\n",
    "\n",
    "\n",
    "df['class'].replace(to_replace=sourceClassLabel, value=sourceClassCode, inplace=True )\n",
    "\n",
    "#find codes which did not match \n",
    "df.loc[~df['class'].isin(sourceClassCode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLAGS and FOOTNOTES\n",
    "# read in motor energy dictionary metadata,\n",
    "metadataXls = pd.ExcelFile('metadata_vehicle_fleet.xlsx')\n",
    "footnoteDictionary= pd.read_excel(metadataXls, sheet_name= 'footnote_metadata', index_col= 0)\n",
    "\n",
    "footnoteDictionaryRelevant = footnoteDictionary.loc[footnoteDictionary['source']== nb_data_source]\n",
    "\n",
    "sourceCodeFootnote = footnoteDictionaryRelevant['source_code'].to_list()\n",
    "outputCodeFootnote = footnoteDictionaryRelevant['output_code'].to_list()\n",
    "\n",
    "df['footnote'].replace(to_replace=sourceCodeFootnote, value= outputCodeFootnote, inplace=True )\n",
    "#find codes which did not match \n",
    "df.loc[~df['footnote'].isin(outputCodeFootnote)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mark no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "what does the missing data mean? Does it mean there were no vehicles of that type? or does it mean that there is no data recorded for that type? \"\"\"\n",
    "'''\n",
    "df.replace(to_replace=':', value='no_data', inplace=True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rearrange data into proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.melt() pivots the table bringing the column headers into a new attribute\n",
    "melt = df.melt(id_vars=['geo'], var_name= 'year')\n",
    "melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## structuring the data into format of datastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the data frame to df\n",
    "df=melted\n",
    "# add in a column of indexes\n",
    "df.index = notebook_id + df.index.astype(str).str.zfill(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename or add all necessary columns\n",
    "df.loc[:,'year_of_measurement']= df.loc[:,'year']\n",
    "# date of measurement is concatonated to year of measurement to achieve desired format\n",
    "df.loc[:,'date_of_measurement']=df['year_of_measurement'].astype(str) + '-03-31'\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:,'geo']= \n",
    "df.loc[:,'process']= 'r'\n",
    "df.loc[:,'vehicle_class']= 'all'\n",
    "df.loc[:,'vehicle_segment']='all'\n",
    "df.loc[:,'motor_energy']= 'all'\n",
    "df.loc[:,'model_year']= 'all'\n",
    "df.loc[:,'year_of_first_registraion']=''\n",
    "df.loc[:,'value']= df['value']\n",
    "df.loc[:,'unit']= 'nr'\n",
    "df.loc[:,'source']= nb_data_source\n",
    "df.loc[:,'accessed']= '2020-06-30'\n",
    "df.loc[:,'notebook']= nb_name\n",
    "df.loc[:,'footnote']= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a finalized dataframe for output with columns in arranged order\n",
    "heading_list= ['year_of_measurement','date_of_measurement','geo','process','vehicle_class','vehicle_segment','motor_energy','model_year','year_of_first_registraion','value','unit','source','accessed','notebook','footnote']\n",
    "df_out= df[heading_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_of_measurement</th>\n",
       "      <th>date_of_measurement</th>\n",
       "      <th>geo</th>\n",
       "      <th>process</th>\n",
       "      <th>vehicle_class</th>\n",
       "      <th>vehicle_segment</th>\n",
       "      <th>drive_train</th>\n",
       "      <th>model_year</th>\n",
       "      <th>year_of_first_registraion</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>source</th>\n",
       "      <th>accessed</th>\n",
       "      <th>notebook</th>\n",
       "      <th>footnote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>003000000000</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>150</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>45053.2</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000001</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>40</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>367</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>56</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>674.465</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000003</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>208</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>479</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000000004</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-03-31</td>\n",
       "      <td>246</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>86.69</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001590</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>788</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>460</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001591</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>800</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>340</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001592</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>894</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>120</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001593</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>716</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>003000001594</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>OICV</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td></td>\n",
       "      <td>335190</td>\n",
       "      <td>nr</td>\n",
       "      <td>OICA</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>003_s_GL_2005_2015_cl(cv)_oica.ipynb</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             year_of_measurement date_of_measurement  geo process  \\\n",
       "003000000000                2005          2005-03-31  150       r   \n",
       "003000000001                2005          2005-03-31   40       r   \n",
       "003000000002                2005          2005-03-31   56       r   \n",
       "003000000003                2005          2005-03-31  208       r   \n",
       "003000000004                2005          2005-03-31  246       r   \n",
       "...                          ...                 ...  ...     ...   \n",
       "003000001590                2015          2015-03-31  788       r   \n",
       "003000001591                2015          2015-03-31  800       r   \n",
       "003000001592                2015          2015-03-31  894       r   \n",
       "003000001593                2015          2015-03-31  716       r   \n",
       "003000001594                2015          2015-03-31    1       r   \n",
       "\n",
       "             vehicle_class vehicle_segment drive_train model_year  \\\n",
       "003000000000          OICV             all         all        all   \n",
       "003000000001          OICV             all         all        all   \n",
       "003000000002          OICV             all         all        all   \n",
       "003000000003          OICV             all         all        all   \n",
       "003000000004          OICV             all         all        all   \n",
       "...                    ...             ...         ...        ...   \n",
       "003000001590          OICV             all         all        all   \n",
       "003000001591          OICV             all         all        all   \n",
       "003000001592          OICV             all         all        all   \n",
       "003000001593          OICV             all         all        all   \n",
       "003000001594          OICV             all         all        all   \n",
       "\n",
       "             year_of_first_registraion    value unit source    accessed  \\\n",
       "003000000000                            45053.2   nr   OICA  2020-06-30   \n",
       "003000000001                                367   nr   OICA  2020-06-30   \n",
       "003000000002                            674.465   nr   OICA  2020-06-30   \n",
       "003000000003                                479   nr   OICA  2020-06-30   \n",
       "003000000004                              86.69   nr   OICA  2020-06-30   \n",
       "...                                ...      ...  ...    ...         ...   \n",
       "003000001590                                460   nr   OICA  2020-06-30   \n",
       "003000001591                                340   nr   OICA  2020-06-30   \n",
       "003000001592                                120   nr   OICA  2020-06-30   \n",
       "003000001593                                110   nr   OICA  2020-06-30   \n",
       "003000001594                             335190   nr   OICA  2020-06-30   \n",
       "\n",
       "                                          notebook footnote  \n",
       "003000000000  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000001  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000002  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000003  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000000004  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "...                                            ...      ...  \n",
       "003000001590  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001591  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001592  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001593  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "003000001594  003_s_GL_2005_2015_cl(cv)_oica.ipynb           \n",
       "\n",
       "[1595 rows x 15 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df_out before saving\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## at this point restart kernel and run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an output file named according to notebook id with relevant data and metadata\n",
    "writer = pd.ExcelWriter(nb_output_workbook, engine='xlsxwriter')\n",
    "df_out.to_excel(writer, sheet_name='data', merge_cells=False)\n",
    "notebook_metadata.to_excel(writer, sheet_name= 'notebook_metadata')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the data from the notebook to the stock dataframe and notebook metadata pickles\n",
    "\n",
    "import pickle\n",
    "# load in the stock DataFrame pickle\n",
    "stock_pickle = pd.read_pickle('stock_df.pickle')\n",
    "\n",
    "# concatenate the out_df to the stock_pickle and remove any duplicate rows\n",
    "stock_df = pd.concat([stock_pickle,df_out]).drop_duplicates()\n",
    "\n",
    "# write the updated stock dataframe to pickle\n",
    "stock_df.to_pickle('stock_df.pickle')\n",
    "\n",
    "# repeat the process for the metadata\n",
    "metadata_pickle = pd.read_pickle('metadata_df.pickle')\n",
    "\n",
    "metadata_df = pd.concat([metadata_pickle, notebook_metadata]).drop_duplicates()\n",
    "\n",
    "metadata_df.to_pickle('metadata_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the stock metadata \n",
    "writer = pd.ExcelWriter('vehicle_fleet_stock.xlsx', engine='xlsxwriter')\n",
    "stock_df.to_excel(writer, sheet_name='data', merge_cells=False)\n",
    "metadata_df.to_excel(writer, sheet_name= 'notebook_metadata')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code initializes the pickle files \n",
    "# df_out.to_pickle('stock_df.pickle')\n",
    "# notebook_metadata.to_pickle('metadata_df.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
